import logging
import random
import json
import tempfile
import boto3
import os
import multiprocessing
import binary2image
from os.path import isfile, join
from os import listdir
from PIL import Image
import numpy as np

logging.basicConfig(
    format='%(levelname)s:%(message)s',
    level=logging.INFO,
    handlers=[
        logging.FileHandler("run_output.log"),
        logging.StreamHandler()
    ])


def load_random_files(samples=10000):
    logging.info(f'Randomly selecting {samples} samples')
    with open(os.path.dirname(os.path.realpath(__file__))+'/DatasetSources/SORELMalwareSHA.json') as f:
        data = json.load(f)
    data_samples = random.sample(data, samples)
    temp_sampes_dir = tempfile.TemporaryDirectory()
    temp_dir = temp_sampes_dir.name
    logging.info(f"The temporary file location is {temp_dir}")
    files = [{'file': d, 'temp_dir': temp_dir} for d in data_samples]
    logging.info(f'Beginning the download of {samples} samples')
    logging.getLogger().setLevel(logging.WARN)
    # create a process pool that uses all cpus
    with multiprocessing.Pool() as pool:
        # call the function for each item in parallel
        res = pool.map_async(download_file, files)
        res.wait()
    logging.getLogger().setLevel(logging.INFO)
    logging.info(f'Beginning the conversion of {samples} samples')
    binary2image.main(input_dir=temp_dir, width=32)
    # images = [join(temp_dir+'/L', f) for f in listdir(temp_dir+'/L') if isfile(join(temp_dir+'/L', f))]
    # for image in images:
    #     shutil.copy(image, dataset_save_location)
    images_location = temp_dir + '/L'
    images = read_images(images_location, width=32)
    logging.info(f'Cleaning up')
    temp_sampes_dir.cleanup()
    return images

def download_file(data):
    f_name = data['file']['sha256']
    temp_dir = data['temp_dir']
    s3 = boto3.resource('s3')
    pretext = '09-DEC-2020/binaries/'
    s3.Bucket('sorel-20m').download_file(pretext+f_name,temp_dir+'/'+f_name)

def read_images(path, width):
    files = [join(path, f) for f in listdir(path) if isfile(join(path, f))]
    images = [Image.open(f).convert('L') for f in files]
    images = [img.resize((width, width)) for img in images]
    images_np = np.asarray([np.asarray(img) for img in images])
    images_np = images_np.reshape((len(images_np), 1, width, width))
    return images_np




if __name__ == '__main__':
    load_random_files(10)