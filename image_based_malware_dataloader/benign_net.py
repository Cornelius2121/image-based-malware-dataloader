import numpy as np
from os import listdir
import os
import logging
from PIL import Image
from os.path import isfile, join


def benign_net(
        path_to_dataset: str = '',
        batch_size: int = 128,
        image_resolution: int = 32,
        datasets=None
):
    # Validate that the parameters are within bounds
    if datasets is None:
        datasets = ['train', 'val']
    if path_to_dataset == '':
        raise Exception("path_to_dataset must be specified")
    if len(datasets) > 3 or len(datasets) < 1:
        raise Exception("datasets must be a list of length 1-3")
    if not np.in1d(datasets, ['train', 'val', 'test']).all():
        raise Exception("datasets must be a list of 'train', 'val', and/or 'test'")
    # define the loaders dictionary with the metadata of what will be loaded
    loaders = {
        'image_resolution': image_resolution,
        'batch_size': batch_size,
        'input_channels': 1
    }
    path_to_dataset = path_to_dataset+'/benign-net'
    logging.info('--- BEGIN LOADING DATASET ---')
    for set in datasets:
        # for each of the datasets that have to be loaded,
        # get the file paths, open the images, convert to grayscale,
        # and resize to defined image resolution
        if set == 'val':
            break
        features = []
        full_labels = []
        logging.info(f'LOADING {set.upper()} SET')
        path = path_to_dataset + f'/{set}'
        files = [f for f in listdir(path) if isfile(join(path, f))]
        files_full = []
        for path, subdirs, files in os.walk(path):
            files = [f for f in listdir(path) if isfile(join(path, f))]
            for name in files:
                if isfile(os.path.join(path, name)) and not name.startswith('.'):
                    files_full.append(os.path.join(path, name))
        images = [Image.open(f).convert('L') for f in files_full]
        images = [img.resize((image_resolution, image_resolution)) for img in images]
        images_np = [np.asarray(img) for img in images]
        features.extend(images_np)
        # Resize the data and check that the samples are in the correct size
        logging.info(f'--- {set.upper()} DATASET LOADING COMPLETE ---')
        logging.info(f'--- BEGIN {set.upper()} DATASET PREPROCESSING ---')
        features = np.asarray([feature for feature in features])
        # Shuffles the dataset
        idx = np.random.choice(len(features), len(features))
        features = features[idx]
        X_train = features.reshape((len(features), 1, image_resolution, image_resolution))
        loaders[set] = X_train
        logging.info(f'--- {set.upper()} DATASET PREPROCESSING COMPLETE ---')
    if 'train' in datasets:
        total_train_len = len(loaders['train'])
        train = loaders['train'][:9/total_train_len]
        val = loaders['train'][9/total_train_len:]
        loaders['train'] = train
        if 'val' in datasets:
            loaders['val'] = val
    return loaders
