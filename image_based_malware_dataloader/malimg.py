import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from torch import Tensor
from sklearn.model_selection import train_test_split
import torch
from os import listdir
from PIL import Image
from os.path import isfile, join


def load_malimg_dataset_img(path_to_dataset: str = 'Datasets/MalImg/malimg_imgs_processed_32',
                            train_test_val_split=None,
                            batch_size: int = 128,
                            image_resolution: int = 32):
    if train_test_val_split is None:
        train_test_val_split = [80, 10, 10]
    if sum(train_test_val_split) != 100:
        raise Exception("train_test_val_split must sum to 100")
    if len(train_test_val_split) != 3:
        raise Exception("train_test_val_split must be a list of length 3")

    labels = ['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.gen!g',
              'C2LOP.P', 'Dialplatform.B', 'Dontovo.A', 'Fakerean', 'Instantaccess', 'Lolyda.AA1', 'Lolyda.AA2',
              'Lolyda.AA3', 'Lolyda.AT', 'Malex.gen!J', 'Obfuscator.AD', 'Rbot!gen', 'Skintrim.N', 'Swizzor.gen!E',
              'Swizzor.gen!I', 'VB.AT', 'Wintrim.BX', 'Yuner.A']
    expected_sample_count = 9339

    features = []
    full_labels = []

    for index, label in enumerate(labels):
        path = path_to_dataset + f'/{label}'
        files = [f for f in listdir(path) if isfile(join(path, f))]
        images = [Image.open(path + f'/{f}').convert('L') for f in files]
        images_np = [np.asarray(img) for img in images]
        features.extend(images_np)
        full_labels.extend([index for i in range(len(images_np))])
    features = np.asarray([feature for feature in features])
    full_labels = np.array([label for label in full_labels])
    if len(full_labels) != expected_sample_count:
        raise Exception(f"Expected {expected_sample_count} samples in dataset, but got {len(full_labels)}")
    full_labels = full_labels.reshape((len(full_labels), 1))
    X_train, X_test, y_train, y_test = train_test_split(features, full_labels, test_size=train_test_val_split[2],
                                                        shuffle=False)

    X_train = X_train.reshape((len(X_train), 1, image_resolution, image_resolution))
    X_test = X_test.reshape((len(X_test), 1, image_resolution, image_resolution))
    new_y_train = np.zeros((len(X_train), len(labels)))
    for ind, val in enumerate(y_train):
        tmp = np.zeros(len(labels))
        tmp[val] = 1
        new_y_train[ind] = tmp
    y_train = new_y_train

    new_y_test = np.zeros((len(X_test), len(labels)))
    for ind, val in enumerate(y_test):
        tmp = np.zeros(len(labels))
        tmp[val] = 1
        new_y_test[ind] = tmp
    y_test = new_y_test

    train_dataset = TensorDataset(Tensor(X_train), torch.argmax(Tensor(y_train), dim=1))
    trainloader = DataLoader(train_dataset, batch_size=batch_size)

    test_dataset = TensorDataset(Tensor(X_test), torch.argmax(Tensor(y_test), dim=1))
    testloader = DataLoader(test_dataset, batch_size=batch_size)
    return trainloader, testloader

if __name__ == '__main__':
    load_malimg_dataset_img(path_to_dataset='../Datasets/MalImg/malimg_imgs_processed_32')